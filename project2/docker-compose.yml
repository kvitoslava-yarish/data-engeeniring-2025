version: "3.9"

x-airflow-env: &airflow_env
  AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
  AIRFLOW__WEBSERVER__RBAC: ${AIRFLOW__WEBSERVER__RBAC}
  AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
  AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
  AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
  AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: "true"
  AIRFLOW__CORE__ENABLE_XCOM_PICKLING: "true"
  TZ: ${TZ}

services:
  clickhouse:
    image: clickhouse/clickhouse-server:24.8
    container_name: clickhouse
    environment:
      TZ: ${TZ}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      CLICKHOUSE_DB: ${CLICKHOUSE_DB}
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./clickhouse/init:/docker-entrypoint-initdb.d
    ports:
      - "8123:8123"
      - "9000:9000"
    networks: [airflow_net]
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 10

  postgres:
    image: postgres:15
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    networks: [airflow_net]
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U airflow -d airflow" ]
      interval: 5s
      timeout: 5s
      retries: 10

  airflow-init:
    build:
      context: ./airflow
    container_name: airflow-init
    command: >
      bash -c "airflow db migrate && 
      airflow users create --role Admin --username ${AIRFLOW_ADMIN_USER} --password ${AIRFLOW_ADMIN_PWD} --firstname Admin --lastname User --email ${AIRFLOW_ADMIN_EMAIL}"
    environment:
      <<: *airflow_env
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW_FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW_SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      AIRFLOW_ADMIN_USER: ${AIRFLOW_ADMIN_USER}
      AIRFLOW_ADMIN_PWD: ${AIRFLOW_ADMIN_PWD}
      AIRFLOW_ADMIN_EMAIL: ${AIRFLOW_ADMIN_EMAIL}
      CLICKHOUSE_HOST: ${CLICKHOUSE_HOST}
      CLICKHOUSE_DB: ${CLICKHOUSE_DB}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      CLICKHOUSE_TCP_PORT: ${CLICKHOUSE_TCP_PORT}
    user: "0:0"
    networks: [airflow_net]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/include:/opt/airflow/include
      - ./dbt:/opt/dbt
    depends_on:
      postgres:
        condition: service_healthy
      clickhouse:
        condition: service_healthy

  airflow-webserver:
    build:
      context: ./airflow
    container_name: airflow-webserver
    restart: always
    environment:
      <<: *airflow_env
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      CLICKHOUSE_HOST: ${CLICKHOUSE_HOST}
      CLICKHOUSE_DB: ${CLICKHOUSE_DB}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      CLICKHOUSE_TCP_PORT: ${CLICKHOUSE_TCP_PORT}
    user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
    networks: [airflow_net]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/include:/opt/airflow/include
      - ./dbt:/opt/dbt
    command: ["webserver"]
    ports:
      - "8080:8080"
    depends_on:
      airflow-scheduler:
        condition: service_started

  airflow-scheduler:
    build:
      context: ./airflow
    container_name: airflow-scheduler
    restart: always
    environment:
      <<: *airflow_env
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      CLICKHOUSE_HOST: ${CLICKHOUSE_HOST}
      CLICKHOUSE_DB: ${CLICKHOUSE_DB}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      CLICKHOUSE_TCP_PORT: ${CLICKHOUSE_TCP_PORT}
    user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
    networks: [airflow_net]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/include:/opt/airflow/include
      - ./dbt:/opt/dbt
    command: [ "scheduler"]
    healthcheck:
      test: [ "CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname $(hostname)" ]
      interval: 10s
      timeout: 10s
      retries: 20
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      clickhouse:
        condition: service_healthy


  dbt-init:
    build:
      context: ./dbt
    image: local/dbt-clickhouse:latest   # shared image Airflow will use
    container_name: dbt-init
    working_dir: /usr/app
    entrypoint: /bin/bash
    command: -c "dbt deps && dbt debug --profiles-dir /usr/app/profiles"
    environment:
      TZ: ${TZ}
      DBT_PROFILES_DIR: /usr/app/profiles
      DBT_HOST: ${DBT_HOST}
      DBT_PORT: ${DBT_PORT}
      DBT_USER: ${DBT_USER}
      DBT_PASSWORD: ${DBT_PASSWORD}
      DBT_SCHEMA: ${DBT_SCHEMA}
      DBT_DATABASE: ${DBT_DATABASE}
    volumes:
      - ./dbt:/usr/app
    depends_on:
      clickhouse:
        condition: service_healthy

#  dbt:
#    build:
#      context: ./dbt
#    container_name: dbt
#    working_dir: /usr/app
#    environment:
#      TZ: ${TZ}
#      DBT_TARGET: ${DBT_TARGET}
#      DBT_SCHEMA: ${DBT_SCHEMA}
#      DBT_HOST: ${DBT_HOST}
#      DBT_PORT: ${DBT_PORT}
#      DBT_USER: ${DBT_USER}
#      DBT_PASSWORD: ${DBT_PASSWORD}
#      DBT_DATABASE: ${DBT_DATABASE}
#      DBT_PROFILES_DIR: /usr/app/profiles
#    volumes:
#      - ./dbt:/usr/app
#    ports:
#      - "8081:8081"
#    command: tail -f /dev/null
#    depends_on:
#      dbt-init:
#        condition: service_completed_successfully

  tabix:
    image: spoonest/clickhouse-tabix-web-client:latest
    container_name: tabix
    ports:
      - "8124:80"
    depends_on:
      clickhouse:
        condition: service_healthy

networks:
  airflow_net:
    driver: bridge

volumes:
  clickhouse_data:
  postgres_data:
  airflow_dags:
  airflow_logs:
  airflow_plugins:
